{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "mingfang\n",
      "yukunh01\n",
      "jianji01\n",
      "yiliang1\n",
      "pengzh01\n",
      "xinchen\n",
      "mingmyao\n",
      "yueguo01\n",
      "cn569306\n",
      "xiongan2\n",
      "yingying\n",
      "B\n",
      "mingfang\n",
      "yukunh01\n",
      "jianji01\n",
      "yiliang1\n",
      "pengzh01\n",
      "xinchen\n",
      "mingmyao\n",
      "yueguo01\n",
      "cn569306\n",
      "yingying\n",
      "xiongan2\n",
      "0:33:37.657142\n"
     ]
    }
   ],
   "source": [
    "#process images\n",
    "from PIL import Image\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isdir, join\n",
    "from datetime import datetime\n",
    "begin = datetime.now()\n",
    "root = r'\\\\fas3000-b.bei.is.keysight.com\\v6\\device_recognize\\origin'\n",
    "root_resized = r'C:\\Zdata\\DL pictures\\Processed'\n",
    "\n",
    "file_indexes = {}\n",
    "for t in ['A', 'B']:\n",
    "    date_indexes = {}\n",
    "    for date in ['1016', '1017', '1018']:\n",
    "        date_indexes[date] = 1\n",
    "    file_indexes[t] = date_indexes\n",
    "\n",
    "def process_image(image_file):\n",
    "    im = Image.open(image_file)\n",
    "    im = im.convert('L')    \n",
    "    x, y = im.size\n",
    "    if (y > x):\n",
    "        im = im.rotate(90, expand=True)        \n",
    "    x, y = im.size    \n",
    "    resize_y = 168\n",
    "    resize_x = 168 * x / y\n",
    "    im.thumbnail((resize_x, resize_y), Image.ANTIALIAS)    \n",
    "    target_x = 224\n",
    "    target_y = 168\n",
    "    new_size = (resize_x/2 - target_x/2, resize_y/2 - target_y/2, resize_x/2 + target_x/2, resize_y/2 + target_y/2)\n",
    "    im = im.crop(new_size)    \n",
    "    return im\n",
    "\n",
    "# types = [f for f in listdir(root) if isdir(join(root, f))]\n",
    "for t in ['A', 'B']:\n",
    "    print(t)\n",
    "    type_folder = join(root, t)\n",
    "    users = [f for f in listdir(type_folder) if isdir(join(type_folder, f))]\n",
    "    for user in users:\n",
    "        print(user)\n",
    "        user_folder = join(type_folder, user)\n",
    "        onoffs = [f for f in listdir(user_folder) if isdir(join(user_folder, f))]\n",
    "        for onoff in onoffs:\n",
    "            onoff_folder = join(user_folder, onoff)\n",
    "            with os.scandir(onoff_folder) as pictures:\n",
    "                for picture in pictures:                      \n",
    "                    stat = picture.stat()\n",
    "                    date = datetime.fromtimestamp(stat.st_mtime)\n",
    "                    if not picture.name.endswith('.jpg'):\n",
    "                        continue\n",
    "                    im = process_image(join(onoff_folder, picture.name))\n",
    "                    dateString = \"%2d%2d\"%(date.month, date.day)\n",
    "                    index = file_indexes[t][dateString]\n",
    "                    im.save(join(root_resized, \"%s_%s_%04d.jpg\"%(t, dateString, index)), \"JPEG\")\n",
    "                    file_indexes[t][dateString] = index + 1\n",
    "                    \n",
    "elapse = datetime.now() - begin\n",
    "print(elapse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:23.817126\n"
     ]
    }
   ],
   "source": [
    "#split data set into training and test\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isdir, join\n",
    "from datetime import datetime\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "begin = datetime.now()\n",
    "processed_folder = r'C:\\Zdata\\DL pictures\\Processed'\n",
    "training_folder = join(processed_folder, 'training')\n",
    "test_folder = join(processed_folder, 'test')\n",
    "\n",
    "def create_folder(folder):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "def classify_image_files(category, date, user, indexes, destination_folder):\n",
    "    create_folder(destination_folder)\n",
    "    for index in indexes:\n",
    "        file_name = \"%s_%s_%04d.jpg\"%(category, date, index)\n",
    "        source_file = join(processed_folder, file_name)\n",
    "        destination_file = join(destination_folder, file_name)\n",
    "        shutil.move(source_file, destination_file)\n",
    "\n",
    "for category in ['A', 'B']:\n",
    "    for date in ['1016', '1017', '1018']:\n",
    "        indexes = list(range(1, 441))\n",
    "        random.shuffle(indexes)\n",
    "        classify_image_files(category, date, user, indexes[:400], training_folder)\n",
    "        classify_image_files(category, date, user, indexes[400:440], test_folder)\n",
    "        \n",
    "elapse = datetime.now() - begin\n",
    "print(elapse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 168, 224, 1)\n",
      "(2400, 2)\n",
      "[[[0.01568627]\n",
      "  [0.01568627]\n",
      "  [0.01568627]\n",
      "  ...\n",
      "  [0.76862745]\n",
      "  [0.76862745]\n",
      "  [0.76862745]]\n",
      "\n",
      " [[0.01568627]\n",
      "  [0.01568627]\n",
      "  [0.01568627]\n",
      "  ...\n",
      "  [0.76862745]\n",
      "  [0.76862745]\n",
      "  [0.76862745]]\n",
      "\n",
      " [[0.01568627]\n",
      "  [0.01568627]\n",
      "  [0.01568627]\n",
      "  ...\n",
      "  [0.76862745]\n",
      "  [0.76862745]\n",
      "  [0.76862745]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.39215686]\n",
      "  [0.37647059]\n",
      "  [0.37254902]\n",
      "  ...\n",
      "  [0.38431373]\n",
      "  [0.38431373]\n",
      "  [0.38823529]]\n",
      "\n",
      " [[0.36862745]\n",
      "  [0.35294118]\n",
      "  [0.37647059]\n",
      "  ...\n",
      "  [0.37647059]\n",
      "  [0.37254902]\n",
      "  [0.37254902]]\n",
      "\n",
      " [[0.38431373]\n",
      "  [0.36862745]\n",
      "  [0.38431373]\n",
      "  ...\n",
      "  [0.36862745]\n",
      "  [0.36078431]\n",
      "  [0.35686275]]]\n",
      "(240, 168, 224, 1)\n",
      "(240, 2)\n",
      "[[[0.25098039]\n",
      "  [0.2627451 ]\n",
      "  [0.27843137]\n",
      "  ...\n",
      "  [0.70980392]\n",
      "  [0.71372549]\n",
      "  [0.71764706]]\n",
      "\n",
      " [[0.25490196]\n",
      "  [0.26666667]\n",
      "  [0.27843137]\n",
      "  ...\n",
      "  [0.70588235]\n",
      "  [0.71372549]\n",
      "  [0.71764706]]\n",
      "\n",
      " [[0.25490196]\n",
      "  [0.26666667]\n",
      "  [0.27843137]\n",
      "  ...\n",
      "  [0.70588235]\n",
      "  [0.70980392]\n",
      "  [0.71372549]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.08235294]\n",
      "  [0.06666667]\n",
      "  [0.04313725]\n",
      "  ...\n",
      "  [0.07058824]\n",
      "  [0.07058824]\n",
      "  [0.0745098 ]]\n",
      "\n",
      " [[0.06666667]\n",
      "  [0.05098039]\n",
      "  [0.03529412]\n",
      "  ...\n",
      "  [0.06666667]\n",
      "  [0.0627451 ]\n",
      "  [0.0627451 ]]\n",
      "\n",
      " [[0.05882353]\n",
      "  [0.04705882]\n",
      "  [0.03137255]\n",
      "  ...\n",
      "  [0.0627451 ]\n",
      "  [0.06666667]\n",
      "  [0.06666667]]]\n",
      "0:05:06.796200\n"
     ]
    }
   ],
   "source": [
    "#load to numpy array\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isdir, join\n",
    "\n",
    "begin = datetime.now()\n",
    "processed_folder = r'C:\\Zdata\\DL pictures\\Processed'\n",
    "training_folder = join(processed_folder, 'training')\n",
    "test_folder = join(processed_folder, 'test')\n",
    "\n",
    "def load_data(data_folder):\n",
    "    image_list = []\n",
    "    label_list = []\n",
    "    with os.scandir(data_folder) as image_files:\n",
    "        for image_file in image_files:                      \n",
    "            if not image_file.name.endswith('.jpg'):\n",
    "                continue\n",
    "            image_array = np.ndarray((168, 224, 1))\n",
    "            image = Image.open(join(data_folder, image_file.name))\n",
    "            width, height = image.size\n",
    "            for y in range(height):\n",
    "                for x in range(width):\n",
    "                    image_array[y][x] = [image.getpixel((x,y))]\n",
    "            image_list.append(image_array)\n",
    "            category = image_file.name[:1]\n",
    "            label_list.append([0 if category == 'A' else 1, 0 if category == 'B' else 1])\n",
    "    images = np.array(image_list, np.int32)\n",
    "    labels = np.array(label_list, np.int32)\n",
    "    return images, labels\n",
    "\n",
    "training_images, training_labels = load_data(training_folder)\n",
    "print(training_images.shape)\n",
    "print(training_labels.shape)\n",
    "\n",
    "training_images = training_images / 255.0\n",
    "print(training_images[0])\n",
    "\n",
    "test_images, test_labels = load_data(test_folder)\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)\n",
    "\n",
    "test_images = test_images / 255.0\n",
    "print(test_images[0])\n",
    "\n",
    "elapse = datetime.now() - begin\n",
    "print(elapse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0\n",
      "Train on 2160 samples, validate on 240 samples\n",
      "Epoch 1/11\n",
      "2160/2160 [==============================] - 292s 135ms/step - loss: 0.7326 - acc: 0.6856 - val_loss: 0.4776 - val_acc: 0.8250\n",
      "Epoch 2/11\n",
      "2160/2160 [==============================] - 271s 125ms/step - loss: 0.4738 - acc: 0.8023 - val_loss: 0.4425 - val_acc: 0.8250\n",
      "Epoch 3/11\n",
      "2160/2160 [==============================] - 266s 123ms/step - loss: 0.3850 - acc: 0.8444 - val_loss: 0.3386 - val_acc: 0.8583\n",
      "Epoch 4/11\n",
      "2160/2160 [==============================] - 259s 120ms/step - loss: 0.3435 - acc: 0.8704 - val_loss: 0.3075 - val_acc: 0.8792\n",
      "Epoch 5/11\n",
      "2160/2160 [==============================] - 262s 121ms/step - loss: 0.2690 - acc: 0.8894 - val_loss: 0.2130 - val_acc: 0.9208\n",
      "Epoch 6/11\n",
      "2160/2160 [==============================] - 267s 124ms/step - loss: 0.2188 - acc: 0.9181 - val_loss: 0.1608 - val_acc: 0.9292\n",
      "Epoch 7/11\n",
      "2160/2160 [==============================] - 267s 124ms/step - loss: 0.1897 - acc: 0.9306 - val_loss: 0.2979 - val_acc: 0.8750\n",
      "Epoch 8/11\n",
      "2160/2160 [==============================] - 257s 119ms/step - loss: 0.1477 - acc: 0.9431 - val_loss: 0.1430 - val_acc: 0.9583\n",
      "Epoch 9/11\n",
      "2160/2160 [==============================] - 269s 125ms/step - loss: 0.1079 - acc: 0.9616 - val_loss: 0.0759 - val_acc: 0.9792\n",
      "Epoch 10/11\n",
      "2160/2160 [==============================] - 258s 119ms/step - loss: 0.0991 - acc: 0.9625 - val_loss: 0.1382 - val_acc: 0.9458\n",
      "Epoch 11/11\n",
      "2160/2160 [==============================] - 258s 120ms/step - loss: 0.0599 - acc: 0.9759 - val_loss: 0.1104 - val_acc: 0.9667\n",
      "0:48:48.837200\n"
     ]
    }
   ],
   "source": [
    "#model\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from datetime import datetime\n",
    "\n",
    "begin = datetime.now()\n",
    "print(tf.__version__)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(input_shape=(168, 224, 1), filters=96, kernel_size=11, strides=4, padding=\"valid\", activation=tf.nn.relu),\n",
    "    keras.layers.AveragePooling2D(pool_size=3, strides=2, padding=\"valid\"),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=5, strides=1, padding=\"same\", activation=tf.nn.relu),\n",
    "    keras.layers.AveragePooling2D(pool_size=3, strides=2, padding=\"valid\"),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(4096, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(2, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "length = len(training_labels)\n",
    "c = np.c_[training_images.reshape(length, -1), training_labels.reshape(length, -1)]\n",
    "np.random.shuffle(c)\n",
    "images = c[:, :37632].reshape((length, 168, 224, 1))\n",
    "labels = c[:, 37632:].reshape((length, 2))\n",
    "\n",
    "model.fit(x=images, y=labels, epochs=11, validation_split=0.1)\n",
    "\n",
    "elapse = datetime.now() - begin\n",
    "print(elapse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 9s 36ms/step\n",
      "Test loss: 0.13169637136161327\n",
      "Test accuracy: 0.9625\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_1016_0005.jpg [0 1] [0.70872504 0.2912749 ]\n",
      "A_1016_0023.jpg [0 1] [0.6395397  0.36046025]\n",
      "A_1017_0050.jpg [0 1] [0.95259416 0.04740584]\n",
      "A_1018_0365.jpg [0 1] [0.9494691  0.05053084]\n",
      "B_1016_0311.jpg [1 0] [0.05471027 0.94528973]\n",
      "B_1017_0376.jpg [1 0] [0.40888053 0.59111947]\n",
      "B_1018_0062.jpg [1 0] [0.29948953 0.7005105 ]\n",
      "B_1018_0345.jpg [1 0] [1.3450760e-04 9.9986553e-01]\n",
      "B_1018_0375.jpg [1 0] [0.4223726  0.57762736]\n"
     ]
    }
   ],
   "source": [
    "#check which images are not predicted correctly\n",
    "predictions = model.predict(test_images)\n",
    "\n",
    "file_names = []\n",
    "with os.scandir(r'C:\\Zdata\\DL pictures\\Processed\\test') as image_files:\n",
    "    for image_file in image_files:                      \n",
    "        if not image_file.name.endswith('.jpg'):\n",
    "            continue\n",
    "        file_names.append(image_file.name)\n",
    "        \n",
    "for index in range(0, len(test_labels)):\n",
    "    result = (test_labels[index][0] - test_labels[index][1]) * (predictions[index][0] - predictions[index][1])\n",
    "    if (result > 0):\n",
    "        continue\n",
    "    print(file_names[index], test_labels[index], predictions[index])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
