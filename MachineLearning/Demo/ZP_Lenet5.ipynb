{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#organize training data, use type A and type B instrument\n",
    "#already resize the pic to 300*300 with padding\n",
    "#80% as train and 20% as test\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "train_folder = r'S:\\\\test\\\\instrument_resize_300'\n",
    "\n",
    "def read_data(data_dir):\n",
    "    image_list = []\n",
    "    label_list = []\n",
    "    for fname in os.listdir(data_dir):\n",
    "        fpath = os.path.join(data_dir, fname)\n",
    "        img_data = Image.open(fpath)\n",
    "        if fname.startswith(\"A\"):\n",
    "            label_list.append(0)\n",
    "        if fname.startswith(\"B\"):\n",
    "            label_list.append(1)\n",
    "        data = np.array(img_data)\n",
    "        image_list.append(data)\n",
    "    return image_list,label_list\n",
    "\n",
    "def get_train_test_data(image_list, label_list):\n",
    "    temp = np.array([image_list,label_list])\n",
    "    temp = temp.transpose()\n",
    "    np.random.shuffle(temp)\n",
    "    \n",
    "    image_list = list(temp[:,0])\n",
    "    label_list = list(temp[:,1])\n",
    "    count = int(len(image_list) * 0.8)\n",
    "    train_images = np.array(image_list[0:count])\n",
    "    train_labels = np.array(label_list[0:count])\n",
    "    test_images = np.array(image_list[count:])\n",
    "    test_labels = np.array(label_list[count:])\n",
    "    return train_images, train_labels, test_images, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get training data and test data, divide 255.0 for normalization\n",
    "from tensorflow import keras\n",
    "image_list, label_list = read_data(train_folder)\n",
    "train_images, train_labels, test_images, test_labels = get_train_test_data(image_list, label_list)\n",
    "\n",
    "train_labels = keras.utils.to_categorical(train_labels)\n",
    "test_labels = keras.utils.to_categorical(test_labels)\n",
    "\n",
    "train_images = train_images/255.0\n",
    "test_images = test_images/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model \n",
    "modelLet5 = keras.Sequential([\n",
    "    keras.layers.Conv2D(input_shape=(300, 300, 3), filters=6, kernel_size=5, padding=\"same\", activation=tf.nn.relu),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    keras.layers.Conv2D(filters=16, kernel_size=5, padding=\"same\", activation=tf.nn.relu),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(120, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(60, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(2, activation=tf.nn.softmax)\n",
    "])\n",
    "modelLet5.compile(optimizer=tf.train.AdamOptimizer(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2086 samples, validate on 232 samples\n",
      "Epoch 1/5\n",
      "2086/2086 [==============================] - 161s 77ms/step - loss: 0.4083 - acc: 0.8126 - val_loss: 0.2379 - val_acc: 0.9224\n",
      "Epoch 2/5\n",
      "2086/2086 [==============================] - 158s 76ms/step - loss: 0.0921 - acc: 0.9679 - val_loss: 0.1814 - val_acc: 0.9181\n",
      "Epoch 3/5\n",
      "2086/2086 [==============================] - 158s 76ms/step - loss: 0.0309 - acc: 0.9899 - val_loss: 0.1835 - val_acc: 0.9483\n",
      "Epoch 4/5\n",
      "2086/2086 [==============================] - 163s 78ms/step - loss: 0.0479 - acc: 0.9818 - val_loss: 0.1688 - val_acc: 0.9440\n",
      "Epoch 5/5\n",
      "2086/2086 [==============================] - 162s 78ms/step - loss: 0.0224 - acc: 0.9928 - val_loss: 0.2066 - val_acc: 0.9440\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x28f34e8db38>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model\n",
    "modelLet5.fit(x=train_images, y=train_labels, epochs=5, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "580/580 [==============================] - 21s 35ms/step\n",
      "Test Loss: 0.17179937947718105\n",
      "Test accuracy: 0.9517241379310345\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "score = modelLet5.evaluate(test_images, test_labels)\n",
    "print('Test Loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
